{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMO415z6bUCU"
      },
      "source": [
        "# **Notebook Setup: Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAmFNXJMsU9J"
      },
      "outputs": [],
      "source": [
        "# Libraries for Data Loading & Pre-processing\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Libraries for developing, training, and running GRU Neural Network\n",
        "import tensorflow as tf\n",
        "\n",
        "# Fallback api to fetch stock data\n",
        "import yfinance\n",
        "\n",
        "# Libraries for Metric Evaluation\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error,\n",
        "    mean_absolute_percentage_error,\n",
        "    mean_squared_error,\n",
        ")\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bBLbspXr6-O"
      },
      "source": [
        "# **Setup: Parameter Adjustment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q77-kv54p9Vt"
      },
      "outputs": [],
      "source": [
        "# Variables & Parameters to adjust below\n",
        "\n",
        "# Data Loading\n",
        "stock = \"TSLA\"\n",
        "split = 0.8  # Test data is automatically calculated based on this\n",
        "\n",
        "# Data Pre-processing\n",
        "rw = 1  # Rollng Window or Input Window size\n",
        "\n",
        "# Keras Layers Paramaters\n",
        "# GRU Layer\n",
        "units = 5\n",
        "activation = \"tanh\"\n",
        "# Dropout Layer\n",
        "dropout = 0.2\n",
        "\n",
        "# Compiling Parameters\n",
        "loss = \"mean_squared_error\"\n",
        "loss_scale_optimizer = tf.keras.optimizers.SGD(\n",
        "    learning_rate=0.01, momentum=0.9, nesterov=False\n",
        ")\n",
        "\n",
        "# Model Fitting Parameters\n",
        "epochs = 3\n",
        "batch_size = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wooPogbqETec"
      },
      "source": [
        "# **Step 1: Data Loading**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVgRGSr00cZd",
        "outputId": "36cec7ad-d81d-4f1c-d299-f608020e5329"
      },
      "outputs": [],
      "source": [
        "# Reused code from my prophet notebook, need to adopt for GRU specifically\n",
        "# Todo, refactor this for GRU specifically\n",
        "try:\n",
        "    # Attempt to load data from local directory first\n",
        "    df = pd.read_csv(f\"../data/{stock}.csv\")\n",
        "    print(\n",
        "        f\"Successfully loaded data for {stock} from local directory '../data/'.\"\n",
        "    )\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load data from local directory: {e}\")\n",
        "    print(f\"Attempting to fetch data for {stock} using yfinance...\")\n",
        "\n",
        "    try:\n",
        "        # Tries to load data from yfinance api since Local methood failed.\n",
        "        stock_data = yfinance.Ticker(stock)\n",
        "        df = stock_data.history(period=\"max\")\n",
        "\n",
        "        # yfinance uses 'Date' as index, reset to a column for consistency\n",
        "        df = df.reset_index()\n",
        "        df.rename(\n",
        "            columns={\n",
        "                \"Date\": \"date\",\n",
        "                \"Close\": \"close\",\n",
        "                \"Volume\": \"volume\",\n",
        "                \"Open\": \"open\",\n",
        "                \"High\": \"high\",\n",
        "                \"Low\": \"low\",\n",
        "            },\n",
        "            inplace=True,\n",
        "        )\n",
        "\n",
        "        df2 = pd.DataFrame()\n",
        "        df2[\"ds\"] = df[\"date\"].dt.date\n",
        "        df2[\"y\"] = df[\"close\"]\n",
        "\n",
        "        df = df2.copy()\n",
        "\n",
        "        if not df.empty:\n",
        "            print(f\"Successfully fetched data for {stock} using yfinance.\")\n",
        "        else:\n",
        "            print(\n",
        "                \"ERROR: No data could be loaded for analysis. Please check the ticker symbol matches yfinance\"\n",
        "            )\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to fetch data for {stock} using yfinance: {e}\")\n",
        "        print(\n",
        "            \"Both methods failed. Please ensure the data file is in '../data/'\"\n",
        "        )\n",
        "        print(f\"or that '{stock}' is a valid ticker symbol on yfinance.\")\n",
        "        df = None  # Ensure df is None if both methods fail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ7kmJmU0aXG",
        "outputId": "bf6fd87d-ce66-4948-f248-e42665a5e8cd"
      },
      "outputs": [],
      "source": [
        "# Displays the last 5 rows of the loaded dataset, check to make sure it's correct\n",
        "if df is not None:\n",
        "    print(df.tail())\n",
        "else:\n",
        "    print(\"Data could not be loaded using either method.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWjyPGng37Di"
      },
      "source": [
        "# **Step 2: Data Pre-Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Nh7d5OI0APj",
        "outputId": "d75c5826-7fe0-45d4-8574-85a2e1048106"
      },
      "outputs": [],
      "source": [
        "# Extract the date and closing price columns\n",
        "dates = df[\"ds\"]\n",
        "closing_prices = df[\"y\"]\n",
        "\n",
        "# Calculate the number of data points for training and testing\n",
        "number_of_data_points = len(df)\n",
        "train_data_size = math.ceil(number_of_data_points * split)\n",
        "print(\"Training Data Split Size:\", train_data_size)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data = pd.DataFrame(\n",
        "    data={\n",
        "        \"Date\": dates[:train_data_size],\n",
        "        \"Close\": closing_prices[:train_data_size],\n",
        "    }\n",
        ")\n",
        "test_data = pd.DataFrame(\n",
        "    data={\n",
        "        \"Date\": dates[train_data_size:],\n",
        "        \"Close\": closing_prices[train_data_size:],\n",
        "    }\n",
        ")\n",
        "\n",
        "# Print the first few rows of the training and testing data\n",
        "print(\"Training data:\")\n",
        "print(train_data.head())\n",
        "print(\"Training Data Shape\", train_data.shape)\n",
        "\n",
        "print(\"Testing data:\")\n",
        "print(test_data.head())\n",
        "print(\"Testing Data Shape\", test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5htUOuW1A37",
        "outputId": "608a2094-9ee6-4404-89b2-4dd0545cbaa4"
      },
      "outputs": [],
      "source": [
        "# Selecting Open Price values for Training Data\n",
        "dataset_train = train_data.Close.values\n",
        "print(\"OG Dataset_train 1 Dimensional:\", dataset_train.shape)\n",
        "\n",
        "# Reshaping 1D to 2D array for Training Data\n",
        "dataset_train = np.reshape(dataset_train, (-1, 1))\n",
        "print(\"New Dataset_train 2 Dimensional:\", dataset_train.shape)\n",
        "\n",
        "\n",
        "# Selecting Open Price values for Testing Data\n",
        "dataset_test = test_data.Close.values\n",
        "print(\"OG Dataset_test 1 Dimensional:\", dataset_test.shape)\n",
        "\n",
        "# Reshaping 1D to 2D array for Testing Data\n",
        "dataset_test = np.reshape(dataset_test, (-1, 1))\n",
        "print(\"New Dataset_test 2 Dimensional:\", dataset_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Co5Cqp02LpP",
        "outputId": "1a2a3540-7ad1-4ae1-8496-158f13fb3647"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "# scaling both datasets, Normalizing values between 0 and 1\n",
        "scaled_train = scaler.fit_transform(dataset_train)\n",
        "scaled_test = scaler.fit_transform(dataset_test)\n",
        "\n",
        "print(\"Training Dataset Normalized\")\n",
        "print(scaled_train[:5])\n",
        "print(\"Normalized Training Dataset Shape:\", scaled_train.shape)\n",
        "\n",
        "print(\"Testing Dataset Normalized\")\n",
        "print(scaled_test[:5])\n",
        "print(\"Normalized Testing Dataset Shape:\", scaled_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To5N_D2u2kOO",
        "outputId": "e72f53ac-5b42-438c-c108-29cd35374a19"
      },
      "outputs": [],
      "source": [
        "# For training set\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in range(rw, len(scaled_train)):\n",
        "    X_train.append(scaled_train[i - rw : i, 0])\n",
        "    y_train.append(scaled_train[i, 0])\n",
        "    if i <= rw:\n",
        "        print(\n",
        "            \"Training set,\", rw, \"Input Window Size to predict 1 Output Value\"\n",
        "        )\n",
        "        print(X_train)\n",
        "        print(y_train)\n",
        "        print()\n",
        "\n",
        "# For testing set\n",
        "X_test = []\n",
        "y_test = []\n",
        "for i in range(rw, len(scaled_test)):\n",
        "    X_test.append(scaled_test[i - rw : i, 0])\n",
        "    y_test.append(scaled_test[i, 0])\n",
        "    if i <= rw:\n",
        "        print(\n",
        "            \"Testing set,\", rw, \"Input Window Size to predict 1 Output Value\"\n",
        "        )\n",
        "        print(X_test)\n",
        "        print(y_test)\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzwMUe7Z2_CN",
        "outputId": "ff72f897-3a36-41d4-908f-62b881293885"
      },
      "outputs": [],
      "source": [
        "# The data is converted to Numpy array\n",
        "\n",
        "# For training set\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# Reshaping\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "y_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"y_train:\", y_train.shape)\n",
        "\n",
        "\n",
        "# For testing set\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# Reshaping\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "y_test = np.reshape(y_test, (y_test.shape[0], 1))\n",
        "print(\"X_test:\", X_test.shape)\n",
        "print(\"y_test:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNjzf_8h4AFM"
      },
      "source": [
        "# **Step 4: Building the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "ndfXjAEt48XC",
        "outputId": "49d81f78-c2d1-410c-a0ed-bb83ff3b2bc1"
      },
      "outputs": [],
      "source": [
        "# Initialising the GRU model\n",
        "model = tf.keras.models.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.GRU(\n",
        "            units, input_shape=(X_train.shape[1], 1), activation=activation\n",
        "        ),\n",
        "        tf.keras.layers.Dropout(dropout),\n",
        "        tf.keras.layers.Dense(1, activation=\"relu\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compiling GRU\n",
        "model.compile(loss=loss, optimizer=loss_scale_optimizer)\n",
        "\n",
        "# Fitting the data\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghbxeyDUdQO4"
      },
      "source": [
        "# **Step 5: Make Forecast**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUvEqtnp4QTK",
        "outputId": "1ac25c05-239a-46de-d328-ec0325b454e2"
      },
      "outputs": [],
      "source": [
        "# predictions with X_test data\n",
        "y_GRU = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kLUWtDBA9Ju"
      },
      "outputs": [],
      "source": [
        "# scaling back from 0-1 to original, Un-Normalize the values\n",
        "y_GRU_O = scaler.inverse_transform(y_GRU)\n",
        "y_test_O = scaler.inverse_transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1Jt88JEUBj7",
        "outputId": "d36b7de8-a481-40ce-a6ad-737f7276842e"
      },
      "outputs": [],
      "source": [
        "# Verifying data shapes\n",
        "print(\"Test Data Shape:\", test_data.shape)\n",
        "print(\"Predicted Data Shape:\", y_GRU_O.shape)\n",
        "print(\"y_test Data Shape:\", y_test_O.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk9wx8dlBHs-"
      },
      "source": [
        "# **Step 6: Visualizing Graphs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "R83IXGhjCLqS",
        "outputId": "04be9c85-5e67-4089-c75c-178009e4e439"
      },
      "outputs": [],
      "source": [
        "plt.style.use(\"fivethirtyeight\")\n",
        "fig, ax = plt.subplots()  # figsize=(18, 12)\n",
        "\n",
        "# Plot for GRU predictions\n",
        "ax.plot(train_data.index, train_data.Close, label=\"Training Data\")\n",
        "ax.plot(test_data.index, test_data.Close, label=\"Testing Data\")\n",
        "ax.plot(test_data.index[rw:], y_GRU_O, label=\"GRU Forecast\")\n",
        "ax.legend()\n",
        "ax.title.set_text(\"GRU\")\n",
        "\n",
        "plt.xlabel(\"Days\")\n",
        "plt.ylabel(\"Share Price\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJgo8L4kd57_"
      },
      "source": [
        "# **Step 7: Evaluate Model Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D5h1tvsFLqx",
        "outputId": "084710e8-62ab-4387-be43-addbad7e8751"
      },
      "outputs": [],
      "source": [
        "# calculate mean squared error\n",
        "mse = mean_squared_error(y_test_O, y_GRU_O)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "\n",
        "# calculate mean absolute error\n",
        "mae = mean_absolute_error(y_test_O, y_GRU_O)\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "\n",
        "# calculate root mean squared error\n",
        "rmse = math.sqrt(mse)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "\n",
        "# calculate mean absolute percentage error\n",
        "mae = mean_absolute_percentage_error(y_test_O, y_GRU_O)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", mae * 100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "LMO415z6bUCU",
        "5bBLbspXr6-O",
        "RNjzf_8h4AFM",
        "Yk9wx8dlBHs-"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.13.7)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
